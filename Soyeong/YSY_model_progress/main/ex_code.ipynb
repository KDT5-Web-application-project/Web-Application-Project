{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 이미지 전처리를 위한 변환\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 이미지 특성 추출을 위한 ResNet 모델 로드\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "modules = list(resnet.children())[:-1]  # 마지막 FC 레이어 제거\n",
    "resnet = nn.Sequential(*modules)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "# 이미지 캡션 생성을 위한 LSTM 모델 정의\n",
    "class CaptioningModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
    "        super(CaptioningModel, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, features, captions, lengths):\n",
    "        embeddings = self.embed(captions)\n",
    "        embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
    "        packed = pack_padded_sequence(embeddings, lengths, batch_first=True) \n",
    "        hiddens, _ = self.lstm(packed)\n",
    "        outputs = self.linear(hiddens[0])\n",
    "        return outputs\n",
    "\n",
    "# 하이퍼파라미터 정의\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "vocab_size = len(vocab)  # 단어 사전 크기\n",
    "num_layers = 1\n",
    "\n",
    "# 모델 초기화\n",
    "model = CaptioningModel(embed_size, hidden_size, vocab_size, num_layers)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 데이터셋 및 데이터로더 설정\n",
    "# 데이터셋 및 데이터로더 설정은 실제 데이터셋과 연결하여 적절한 설정이 필요합니다.\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, captions, lengths in dataloader:\n",
    "        images = images.cuda()\n",
    "        captions = captions.cuda()\n",
    "        targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
    "        \n",
    "        # 이미지 특성 추출\n",
    "        features = resnet(images)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        \n",
    "        # 예측\n",
    "        outputs = model(features, captions, lengths)\n",
    "        \n",
    "        # 손실 계산 및 역전파\n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 로그 출력\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
